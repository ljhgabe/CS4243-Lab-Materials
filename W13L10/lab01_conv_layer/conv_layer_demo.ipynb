{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Convolutional layer - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a convolutional module\n",
    "* inputs:  2 channels\n",
    "* output:  5 activation maps \n",
    "* filters are 3x3\n",
    "* padding with one layer of zero to not shrink anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Conv2d( 2 , 5 ,  kernel_size=3,  padding=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an input 2 x 6 x 6  (two channels, each one has 6 x 6 pixels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9647, 0.6641, 0.1846, 0.0741, 0.2426, 0.0286],\n",
      "          [0.2926, 0.2690, 0.8945, 0.7917, 0.6449, 0.4339],\n",
      "          [0.4199, 0.9387, 0.3030, 0.7605, 0.5784, 0.1366],\n",
      "          [0.0920, 0.2539, 0.1089, 0.0882, 0.4449, 0.9903],\n",
      "          [0.0181, 0.6897, 0.2516, 0.8399, 0.7515, 0.3681],\n",
      "          [0.6694, 0.0813, 0.5470, 0.1661, 0.7311, 0.2856]],\n",
      "\n",
      "         [[0.0572, 0.5530, 0.5090, 0.3118, 0.4822, 0.0546],\n",
      "          [0.6331, 0.2684, 0.6874, 0.0646, 0.2393, 0.4566],\n",
      "          [0.4991, 0.1681, 0.3625, 0.3109, 0.8576, 0.1604],\n",
      "          [0.5816, 0.0894, 0.6019, 0.9650, 0.5826, 0.2410],\n",
      "          [0.9037, 0.5362, 0.3347, 0.6226, 0.9154, 0.0774],\n",
      "          [0.7821, 0.1263, 0.7604, 0.9761, 0.5548, 0.0411]]]])\n",
      "torch.Size([1, 2, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "bs=1\n",
    "\n",
    "x=torch.rand(bs,2,6,6)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed it to the convolutional layer: the output should have 5 channels (each one is 6x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1464, -0.5058, -0.4121, -0.3813, -0.1551, -0.2146],\n",
      "          [-0.1091, -0.1937, -0.4113, -0.4900, -0.4752, -0.3575],\n",
      "          [-0.1968, -0.2069, -0.5147, -0.5477, -0.3661, -0.1405],\n",
      "          [-0.3232, -0.2430, -0.4195, -0.3464, -0.4819, -0.2669],\n",
      "          [-0.2057, -0.3815, -0.4011, -0.6929, -0.5494, -0.2856],\n",
      "          [ 0.2158, -0.4186,  0.0138, -0.1730,  0.0374, -0.2357]],\n",
      "\n",
      "         [[ 0.0326,  0.3959,  0.2708,  0.3268,  0.2733,  0.2370],\n",
      "          [-0.0920,  0.4574,  0.1929,  0.4797,  0.2473,  0.2792],\n",
      "          [ 0.2269,  0.2934,  0.5939,  0.0310,  0.1756,  0.4366],\n",
      "          [ 0.1510,  0.0887,  0.2965,  0.3478,  0.3414,  0.1654],\n",
      "          [ 0.3653,  0.3119,  0.6454,  0.2852,  0.3365,  0.3320],\n",
      "          [ 0.3551,  0.4914,  0.2409,  0.5954,  0.4347,  0.2755]],\n",
      "\n",
      "         [[ 0.0403,  0.0786,  0.4327,  0.0157,  0.0642,  0.1806],\n",
      "          [ 0.3882,  0.2421,  0.1530,  0.2215,  0.3505,  0.1158],\n",
      "          [ 0.1697,  0.1244,  0.3598,  0.3732,  0.4586,  0.4285],\n",
      "          [ 0.4907,  0.3364,  0.4214,  0.2710,  0.2338,  0.0839],\n",
      "          [ 0.3489, -0.3433,  0.1847,  0.1535,  0.4897,  0.1452],\n",
      "          [ 0.1153,  0.2302,  0.2669,  0.0721,  0.1907,  0.4729]],\n",
      "\n",
      "         [[-0.0360,  0.1642,  0.3257,  0.4081,  0.1841,  0.3494],\n",
      "          [ 0.1032,  0.2319, -0.1029, -0.1142,  0.3707,  0.2799],\n",
      "          [-0.0367, -0.1640,  0.0386, -0.0038,  0.2665,  0.4206],\n",
      "          [-0.0241,  0.3080,  0.1909,  0.0266,  0.2889,  0.1669],\n",
      "          [ 0.1545, -0.0705, -0.0506,  0.0191,  0.1389,  0.3643],\n",
      "          [-0.0852, -0.0449, -0.1369, -0.0463, -0.1860, -0.1205]],\n",
      "\n",
      "         [[-0.1925, -0.2259, -0.1972, -0.0347,  0.0645,  0.0102],\n",
      "          [ 0.1180, -0.1686, -0.1686, -0.3588, -0.2420, -0.2505],\n",
      "          [-0.0371, -0.1183, -0.0901, -0.2361, -0.2311, -0.2995],\n",
      "          [ 0.2258, -0.2436,  0.2367,  0.0642, -0.2452, -0.4158],\n",
      "          [-0.0117, -0.0458, -0.0610, -0.0914, -0.4276, -0.2875],\n",
      "          [ 0.2252, -0.1837,  0.1722,  0.1150, -0.1843, -0.3350]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n",
      "torch.Size([1, 5, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "y=mod(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the 5 filters.\n",
    "* Our filters are 2x3x3\n",
    "* Each of the filter has 2 channels because the inputs have two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0769,  0.0854, -0.0457],\n",
      "          [-0.2278,  0.1797, -0.2205],\n",
      "          [-0.1373,  0.1309, -0.1921]],\n",
      "\n",
      "         [[-0.2324,  0.0508,  0.1103],\n",
      "          [-0.0557,  0.0228, -0.0676],\n",
      "          [-0.1515, -0.2187, -0.0543]]],\n",
      "\n",
      "\n",
      "        [[[-0.0162, -0.1215, -0.0105],\n",
      "          [ 0.2319, -0.1407,  0.0846],\n",
      "          [-0.0128, -0.0090, -0.1557]],\n",
      "\n",
      "         [[-0.1215,  0.2144, -0.0722],\n",
      "          [ 0.2164,  0.1504,  0.0624],\n",
      "          [-0.0099, -0.1855,  0.2224]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2247, -0.0227,  0.1882],\n",
      "          [ 0.1728, -0.2182, -0.1315],\n",
      "          [-0.1470,  0.2327,  0.1637]],\n",
      "\n",
      "         [[ 0.2089,  0.1279, -0.0395],\n",
      "          [-0.2204, -0.1502, -0.0791],\n",
      "          [-0.1176,  0.2314, -0.1635]]],\n",
      "\n",
      "\n",
      "        [[[-0.0567,  0.1631, -0.0448],\n",
      "          [ 0.1037, -0.1097, -0.1254],\n",
      "          [ 0.2014,  0.1393, -0.0822]],\n",
      "\n",
      "         [[-0.2334,  0.0062, -0.0660],\n",
      "          [-0.0554, -0.0243,  0.1007],\n",
      "          [ 0.2226,  0.1079, -0.1888]]],\n",
      "\n",
      "\n",
      "        [[[-0.0275, -0.0402,  0.1873],\n",
      "          [-0.1531, -0.1483, -0.1436],\n",
      "          [ 0.1848, -0.1573, -0.0067]],\n",
      "\n",
      "         [[-0.2103,  0.0290,  0.1645],\n",
      "          [-0.0098,  0.0435,  0.0835],\n",
      "          [-0.1490, -0.0220,  0.0387]]]], requires_grad=True)\n",
      "torch.Size([5, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(mod.weight)\n",
    "\n",
    "print(mod.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
